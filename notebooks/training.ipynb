{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58241/1212248370.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATAFRAME_PATH = \"../../dataset.csv\"\n",
    "IMAGES_PATH = \"../../dataset/images\"\n",
    "MODEL_PATH = \"../model\"\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing files created within this projects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ..model.utils import (\n",
    "#     its_xyxy_time,\n",
    "#     its_denormalize_time,\n",
    "#     get_solar_elevation,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, boxes = zip(*batch)\n",
    "    \n",
    "    # Stack images (they are all the same size after transform)\n",
    "    images = torch.stack(images)\n",
    "    \n",
    "    # Pad the boxes\n",
    "    max_num_boxes = max(box.size(0) for box in boxes)\n",
    "    padded_boxes = []\n",
    "    for box in boxes:\n",
    "        if box.size(0) < max_num_boxes:\n",
    "            padded_box = torch.cat([box, torch.zeros((max_num_boxes - box.size(0), 5))], dim=0)\n",
    "        else:\n",
    "            padded_box = box\n",
    "        padded_boxes.append(padded_box)\n",
    "    \n",
    "    padded_boxes = torch.stack(padded_boxes)\n",
    "    \n",
    "    return images, padded_boxes\n",
    "\n",
    "\n",
    "def resize_with_padding(img, target_size=(200, 200), padding_color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Resize an image while maintaining aspect ratio and add padding to fill the empty space.\n",
    "\n",
    "    :param image: input image.\n",
    "    :param target_size: Tuple (width, height) of the target size.\n",
    "    :param padding_color: Tuple (B, G, R) color value for padding. Default is white (255, 255, 255).\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    original_height, original_width = img.shape[:2]\n",
    "\n",
    "    # Calculate the ratio to maintain aspect ratio\n",
    "    img_ratio = original_width / original_height\n",
    "    target_ratio = target_size[0] / target_size[1]\n",
    "\n",
    "    if img_ratio > target_ratio:\n",
    "        # Image is wider than the target ratio, fit to width\n",
    "        new_width = target_size[0]\n",
    "        new_height = int(new_width / img_ratio)\n",
    "    else:\n",
    "        # Image is taller than the target ratio, fit to height\n",
    "        new_height = target_size[1]\n",
    "        new_width = int(new_height * img_ratio)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Create a new image with the target size and padding color\n",
    "    padded_img = np.full((target_size[1], target_size[0], 3), padding_color, dtype=np.uint8)\n",
    "\n",
    "    # Calculate the padding offsets\n",
    "    x_offset = (target_size[0] - new_width) // 2\n",
    "    y_offset = (target_size[1] - new_height) // 2\n",
    "\n",
    "    # Insert the resized image into the padded image\n",
    "    padded_img[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized_img\n",
    "    return padded_img\n",
    "\n",
    "def denormalize_yolo_box(box, img_width, img_height):\n",
    "    x_center, y_center, width, height = box\n",
    "\n",
    "    # Scale normalized coordinates to image dimensions\n",
    "    x_center = float(x_center) * img_width\n",
    "    y_center = float(y_center) * img_height\n",
    "    width = float(width) * img_width\n",
    "    height = float(height) * img_height\n",
    "\n",
    "    # Convert from [x_center, y_center, width, height] to [x_min, y_min, x_max, y_max]\n",
    "    x_min = int(x_center - width / 2)\n",
    "    y_min = int(y_center - height / 2)\n",
    "    x_max = int(x_center + width / 2)\n",
    "    y_max = int(y_center + height / 2)\n",
    "\n",
    "    return [x_min, y_min, x_max, y_max]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_path, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.images_path = images_path\n",
    "        self.target_shape = (100, 100)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        \n",
    "        img_path = row['image']\n",
    "        img_path = os.path.join(self.images_path, img_path)\n",
    "        height = float(row['height'])\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        bbox = list(map(float, row['bbox'].split(\" \")))\n",
    "        denorm_bbox = denormalize_yolo_box(bbox, img_width=image.shape[1], img_height=image.shape[0])\n",
    "        image = image[denorm_bbox[1] : denorm_bbox[3], denorm_bbox[0] : denorm_bbox[2]]\n",
    "        image = resize_with_padding(image, target_size=self.target_shape)\n",
    "    \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(height)\n",
    "\n",
    "# Example transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms as T\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import copy\n",
    "import numpy as np\n",
    "import os   \n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from util.util import train_test_split, write_train_file\n",
    "\n",
    "# ? remove printing of warnings5\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from model.layers import Model\n",
    "from model.dataset import cast_to_device\n",
    "from model.loss import RMSELoss, combining_loss\n",
    "\n",
    "sys.path.remove(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cropped(\n",
    "    model,\n",
    "    data_loaders: dict,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    writer,\n",
    "    num_epochs=10,\n",
    "    device=\"cpu\",\n",
    "    shd_loss_weight=1.0,\n",
    "):\n",
    "    ...\n",
    "    print(\"TRAINING STARTED\")\n",
    "\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    last_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1000000\n",
    "    counters = {\"train\": 0, \"val\": 0}\n",
    "\n",
    "    time_str = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    os.makedirs(f\"weights/{time_str}\", exist_ok=True)\n",
    "    write_train_file(\n",
    "        model, optimizer, loss_fn, num_epochs, shd_loss_weight, f\"weights/{time_str}\"\n",
    "    )\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print(f\"Epoch {epoch} / {num_epochs - 1}\", end=\"\\t\")\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            elif phase == \"val\":\n",
    "                model.eval()\n",
    "\n",
    "            running_height_loss = 0.0\n",
    "\n",
    "            for x in data_loaders[phase]:\n",
    "                counters[phase] += 1\n",
    "\n",
    "                image, labels_height = x\n",
    "                image = image.to(device)\n",
    "                labels_height = labels_height.to(device)\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    pred_shd_len, pred_solar_angle, pred_height = model(image)\n",
    "                    pred_shd_len = pred_shd_len.squeeze()\n",
    "                    pred_height = pred_height.squeeze()\n",
    "                    pred_solar_angle = pred_solar_angle.squeeze()\n",
    "\n",
    "                    height_loss = loss_fn(pred_height, labels_height)\n",
    "                    \n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        height_loss.backward()\n",
    "                        # torch.nn.utils.clip_grad_norm_(\n",
    "                        #     model.parameters(), max_norm=10, norm_type=1\n",
    "                        # )\n",
    "                        optimizer.step()\n",
    "\n",
    "                    writer.add_scalar(\n",
    "                        f\"Loss Height/{phase} fast\", height_loss.item(), counters[phase]\n",
    "                    )\n",
    "                    # print(f\"Loss Shadow Length/{phase}\", shd_loss.item(), epoch)\n",
    "\n",
    "                    running_height_loss += height_loss.item()\n",
    "\n",
    "            height_epoch_loss = running_height_loss / (\n",
    "                len(data_loaders[phase].dataset) / data_loaders[phase].batch_size\n",
    "            )\n",
    "\n",
    "            writer.add_scalar(f\"Loss Height/{phase}\", height_epoch_loss, epoch)\n",
    "\n",
    "            print(f\"{phase} height loss: {height_epoch_loss:.4f}\", end=\"\\t\")\n",
    "\n",
    "            if phase == \"val\" and height_epoch_loss < best_loss:\n",
    "                best_loss = height_epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, os.path.join(\"weights\", time_str, \"best.pt\"))\n",
    "\n",
    "            if phase == \"val\":\n",
    "                val_loss_history.append(height_epoch_loss)\n",
    "                last_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(last_model_wts, os.path.join(\"weights\", time_str, \"last.pt\"))\n",
    "\n",
    "            if phase == \"train\":\n",
    "                train_loss_history.append(height_epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Training Complete\")\n",
    "    print(f\"Best Validation Loss: {best_loss:.4f}\")\n",
    "\n",
    "    return val_loss_history, train_loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    device = torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Training on device:\", device)\n",
    "\n",
    "    df = pd.read_csv(args.data)\n",
    "    train_df, val_df = train_test_split(df)\n",
    "\n",
    "    train_df.to_csv(\"train.csv\", index=False)\n",
    "    val_df.to_csv(\"val.csv\", index=False)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = DataFrameDataset(train_df, IMAGES_PATH, transform=transform)\n",
    "    val_dataset = DataFrameDataset(val_df, IMAGES_PATH, transform=transform)\n",
    "\n",
    "    dataloaders = {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True),\n",
    "        \"val\": DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True),\n",
    "    }\n",
    "\n",
    "    model = Model(shd_len_backbone=args.model, pretrained=args.pretrained).to(device)\n",
    "\n",
    "    if args.optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), lr=args.lr, weight_decay=args.wd\n",
    "        )\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(), lr=args.lr, weight_decay=args.wd\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Optimizer not supported\")\n",
    "\n",
    "    if args.loss == \"l1\":\n",
    "        loss_fn = torch.nn.L1Loss()\n",
    "    elif args.loss == \"mse\":\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "    elif args.loss == \"smoothl1\":\n",
    "        loss_fn = torch.nn.SmoothL1Loss()\n",
    "    elif args.loss == \"huber\":\n",
    "        loss_fn = torch.nn.HuberLoss()\n",
    "    elif args.loss == \"rmse\":\n",
    "        loss_fn = RMSELoss()\n",
    "    else:\n",
    "        raise ValueError(\"Loss not supported\")\n",
    "\n",
    "    if args.multi_gpu:\n",
    "        model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    _, _ = train_cropped(\n",
    "        model,\n",
    "        dataloaders,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        writer,\n",
    "        num_epochs=args.epochs,\n",
    "        device=device,\n",
    "        shd_loss_weight=args.shd_loss_weight,\n",
    "    )\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Training Arguments*******\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpu': 0,\n",
       " 'data': '../dataset.csv',\n",
       " 'optimizer': 'adam',\n",
       " 'batch_size': 64,\n",
       " 'epochs': 50,\n",
       " 'multi_gpu': False,\n",
       " 'loss': 'l1',\n",
       " 'model': 'resnet18',\n",
       " 'pretrained': False,\n",
       " 'shd_loss_weight': 0,\n",
       " 'lr': 0.0001,\n",
       " 'wd': 1e-05}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "# Create a Namespace object with your arguments\n",
    "args = Namespace(\n",
    "    gpu=0,\n",
    "    data='../dataset.csv',\n",
    "    optimizer='adam',\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    multi_gpu=False,\n",
    "    loss='l1',\n",
    "    model='resnet18',\n",
    "    pretrained=False,\n",
    "    shd_loss_weight=0,\n",
    "    lr=0.0001,\n",
    "    wd=1e-05\n",
    ")\n",
    "\n",
    "# Convert the Namespace object to a dictionary\n",
    "args_dict = vars(args)\n",
    "\n",
    "\n",
    "# Print the dictionary to verify\n",
    "print(\"*******Training Arguments*******\")\n",
    "display(args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda:0\n",
      "TRAINING STARTED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 49\ttrain height loss: 57.0000\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:03<02:36,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:03<01:19,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:04<00:54,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:04<00:43,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:05<00:36,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:06<00:34,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:07<00:33,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:07<00:29,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:08<00:27,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:08<00:25,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:09<00:23,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:09<00:22,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:10<00:22,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:11<00:21,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:11<00:20,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:12<00:19,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:12<00:19,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:13<00:18,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:13<00:17,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:14<00:16,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:14<00:16,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:15<00:16,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:16<00:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:16<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:17<00:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:17<00:13,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:18<00:12,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:18<00:12,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:19<00:11,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:20<00:11,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:20<00:11,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:21<00:10,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:21<00:09,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [00:22<00:09,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:23<00:09,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:23<00:08,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:24<00:08,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:25<00:07,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:25<00:06,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:26<00:05,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:26<00:05,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:27<00:04,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:27<00:04,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:28<00:03,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:29<00:02,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [00:29<00:02,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:30<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:30<00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:31<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49 / 49\ttrain height loss: nan\tval height loss: nan\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:31<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "Training Complete\n",
      "Best Validation Loss: 1000000.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
